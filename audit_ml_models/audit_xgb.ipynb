{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4435b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.1.0-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5f428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay, accuracy_score, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "import os,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../dataset\"\n",
    "OUTPUT_DIR = \"../results\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"UNSW_NB15_training-set.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"UNSW_NB15_testing-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfac730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(train_csv, test_csv):\n",
    "    train = pd.read_csv(train_csv, low_memory=False)\n",
    "    test  = pd.read_csv(test_csv,  low_memory=False)\n",
    "    for df in (train, test):\n",
    "        df.columns = [c.strip().lower() for c in df.columns]\n",
    "    # expect 'label' present\n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = load_data(TRAIN_CSV, TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09a6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean(df, drop_attack_cat=True):\n",
    "    df = df.copy()\n",
    "    drop_candidates = [c for c in [\"id\", \"label.1\", \"stime\", \"ltime\", \"timestamp\", \"time\"] if c in df.columns]\n",
    "    if drop_candidates:\n",
    "        df = df.drop(columns=drop_candidates)\n",
    "    y = df[\"label\"].astype(int)\n",
    "    df = df.drop(columns=[\"label\"])\n",
    "    if drop_attack_cat and \"attack_cat\" in df.columns:\n",
    "        df = df.drop(columns=[\"attack_cat\"])\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for c in cat_cols:\n",
    "        df[c] = pd.factorize(df[c], sort=True)[0]\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = StandardScaler().fit_transform(df.values)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aa058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cls(model_name, y_true, y_hat, proba=None):\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average='binary', zero_division=0)\n",
    "    auc = None\n",
    "    if proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, proba)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_att\": p,\n",
    "        \"recall_att\": r,\n",
    "        \"f1_att\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }\n",
    "\n",
    "def show_report(name, y_true, y_hat):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(confusion_matrix(y_true, y_hat))\n",
    "    print(classification_report(y_true, y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08648312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Classifier ===\n",
      "[[25018 11982]\n",
      " [ 7314 38018]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7738    0.6762    0.7217     37000\n",
      "           1     0.7604    0.8387    0.7976     45332\n",
      "\n",
      "    accuracy                         0.7656     82332\n",
      "   macro avg     0.7671    0.7574    0.7596     82332\n",
      "weighted avg     0.7664    0.7656    0.7635     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean(train_df)\n",
    "X_test,  y_test  = clean(test_df)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "        n_estimators=700,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1])  # handle imbalance\n",
    "    )\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_hat_xgb = xgb_clf.predict(X_test)\n",
    "try:\n",
    "    proba_xgb = xgb_clf.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    proba_xgb = None\n",
    "    \n",
    "show_report(\"XGBoost Classifier\", y_test, y_hat_xgb)\n",
    "res_xgb = eval_cls(\"XGB\", y_test, y_hat_xgb, proba_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df56e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"XG Boost\"\n",
    "cm = confusion_matrix(y_test, y_hat_xgb)\n",
    "pd.DataFrame(cm, index=[\"Actual_0\",\"Actual_1\"], columns=[\"Pred_0\",\"Pred_1\"])\\\n",
    "  .to_csv(os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_cm.csv\"), index=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay(cm).plot(ax=ax, colorbar=False)\n",
    "ax.set_title(f\"{MODEL_NAME} Confusion Matrix\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_cm.png\"), dpi=160)\n",
    "plt.close(fig)\n",
    "\n",
    "rep = classification_report(y_test, y_hat_xgb, digits=4)\n",
    "with open(os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_report.txt\"), \"w\") as f:\n",
    "    f.write(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0974ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if proba_xgb is not None:\n",
    "        fig, ax = plt.subplots()\n",
    "        RocCurveDisplay.from_predictions(y_test, proba_xgb, ax=ax)\n",
    "        ax.set_title(f\"{MODEL_NAME} ROC\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(OUTPUT_DIR, f\"{MODEL_NAME}_roc.png\"), dpi=160)\n",
    "        plt.close(fig)\n",
    "except NameError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
