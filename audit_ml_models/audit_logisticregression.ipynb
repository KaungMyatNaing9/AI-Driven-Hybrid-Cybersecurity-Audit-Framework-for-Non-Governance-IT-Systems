{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbdc3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay, accuracy_score, precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef772a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../dataset\"\n",
    "OUTPUT_DIR = \"../results\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"UNSW_NB15_training-set.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"UNSW_NB15_testing-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b14c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(train_csv, test_csv):\n",
    "    train = pd.read_csv(train_csv, low_memory=False)\n",
    "    test  = pd.read_csv(test_csv,  low_memory=False)\n",
    "    for df in (train, test):\n",
    "        df.columns = [c.strip().lower() for c in df.columns]\n",
    "    # expect 'label' present\n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = load_data(TRAIN_CSV, TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390b88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean(df, drop_attack_cat=True):\n",
    "    df = df.copy()\n",
    "    drop_candidates = [c for c in [\"id\", \"label.1\", \"stime\", \"ltime\", \"timestamp\", \"time\"] if c in df.columns]\n",
    "    if drop_candidates:\n",
    "        df = df.drop(columns=drop_candidates)\n",
    "    y = df[\"label\"].astype(int)\n",
    "    df = df.drop(columns=[\"label\"])\n",
    "    if drop_attack_cat and \"attack_cat\" in df.columns:\n",
    "        df = df.drop(columns=[\"attack_cat\"])\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for c in cat_cols:\n",
    "        df[c] = pd.factorize(df[c], sort=True)[0]\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = StandardScaler().fit_transform(df.values)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2dbe1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cls(model_name, y_true, y_hat, proba=None):\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average='binary', zero_division=0)\n",
    "    auc = None\n",
    "    if proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, proba)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_att\": p,\n",
    "        \"recall_att\": r,\n",
    "        \"f1_att\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }\n",
    "\n",
    "def show_report(name, y_true, y_hat):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(confusion_matrix(y_true, y_hat))\n",
    "    print(classification_report(y_true, y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c18c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "[[31383  5617]\n",
      " [ 7001 38331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8176    0.8482    0.8326     37000\n",
      "           1     0.8722    0.8456    0.8587     45332\n",
      "\n",
      "    accuracy                         0.8467     82332\n",
      "   macro avg     0.8449    0.8469    0.8456     82332\n",
      "weighted avg     0.8477    0.8467    0.8470     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean(train_df)\n",
    "X_test,  y_test  = clean(test_df)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=None)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat_lr = logreg.predict(X_test)\n",
    "try:\n",
    "    proba_lr = logreg.predict_proba(X_test)[:,1]\n",
    "except Exception:\n",
    "    proba_lr = None\n",
    "\n",
    "show_report(\"Logistic Regression\", y_test, y_hat_lr)\n",
    "res_lr = eval_cls(\"LogReg\", y_test, y_hat_lr, proba_lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
