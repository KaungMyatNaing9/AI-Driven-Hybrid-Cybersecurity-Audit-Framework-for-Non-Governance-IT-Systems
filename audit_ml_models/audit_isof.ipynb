{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea125f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay, accuracy_score, precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d10bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../dataset\"\n",
    "OUTPUT_DIR = \"../results\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) #if results directory does not exist, create it\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"UNSW_NB15_training-set.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"UNSW_NB15_testing-set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d683048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_data(train_csv, test_csv):\n",
    "    train = pd.read_csv(train_csv, low_memory=False)\n",
    "    test  = pd.read_csv(test_csv,  low_memory=False)\n",
    "    for df in (train, test):\n",
    "        df.columns = [c.strip().lower() for c in df.columns]\n",
    "    # expect 'label' present\n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = load_data(TRAIN_CSV, TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47d18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean(df, drop_attack_cat=True):\n",
    "    df = df.copy()\n",
    "    drop_candidates = [c for c in [\"id\", \"label.1\", \"stime\", \"ltime\", \"timestamp\", \"time\"] if c in df.columns]\n",
    "    if drop_candidates:\n",
    "        df = df.drop(columns=drop_candidates)\n",
    "    y = df[\"label\"].astype(int)\n",
    "    df = df.drop(columns=[\"label\"])\n",
    "    if drop_attack_cat and \"attack_cat\" in df.columns:\n",
    "        df = df.drop(columns=[\"attack_cat\"])\n",
    "    cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    for c in cat_cols:\n",
    "        df[c] = pd.factorize(df[c], sort=True)[0]\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = StandardScaler().fit_transform(df.values)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beeec2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cls(model_name, y_true, y_hat, proba=None):\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_hat, average='binary', zero_division=0)\n",
    "    auc = None\n",
    "    if proba is not None:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, proba)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_att\": p,\n",
    "        \"recall_att\": r,\n",
    "        \"f1_att\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }\n",
    "\n",
    "def show_report(name, y_true, y_hat):\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(confusion_matrix(y_true, y_hat))\n",
    "    print(classification_report(y_true, y_hat, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b0e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Isolation Forest ===\n",
      "[[ 1703 35297]\n",
      " [ 5131 40201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2492    0.0460    0.0777     37000\n",
      "           1     0.5325    0.8868    0.6654     45332\n",
      "\n",
      "    accuracy                         0.5090     82332\n",
      "   macro avg     0.3908    0.4664    0.3716     82332\n",
      "weighted avg     0.4052    0.5090    0.4013     82332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean(train_df)\n",
    "X_test,  y_test  = clean(test_df)\n",
    "\n",
    "isof = IsolationForest(n_estimators=300, contamination=0.1,max_samples=0.8, random_state=42,n_jobs=-1)\n",
    "isof.fit(X_train)\n",
    "y_pred_raw = isof.predict(X_test)\n",
    "y_hat = np.where(y_pred_raw == -1, 1, 0)\n",
    "\n",
    "show_report(\"Isolation Forest\", y_test, y_hat)\n",
    "res_isof = eval_cls(\"IsoF\", y_test, y_hat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
